{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3cbea3-88c6-4ded-af2c-26a9e6e02753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e7c03d1-d955-4e51-be01-1653bbebd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_analysis(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Fill missing values with median for numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    # Fill missing values with mode for categorical columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Data Summary\n",
    "    summary = df.describe(include='all').to_string()\n",
    "    \n",
    "    # Missing Values\n",
    "    missing_values = df.isnull().sum().to_string()\n",
    "\n",
    "    # Generate AI Insights\n",
    "    insights = generate_ai_insights(summary)\n",
    "    \n",
    "    # Generate Data Visualizations\n",
    "    plot_paths = generate_visualizations(df)\n",
    "    \n",
    "    return f\"\\n Data Loaded Successfully!\\n\\n Summary:\\n{summary}\\n\\n Missing Values:\\n{missing_values}\\n\\n AI Insights:\\n{insights}\", plot_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd561c9c-bac0-4cc5-bcbb-0675518cf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_ai_insights(df_summary):\n",
    "    prompt = f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content'] if 'message' in response else response['messages'][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eacaee2d-b120-427d-abc1-535510540fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(df):\n",
    "    plot_paths = []\n",
    "    \n",
    "    # Histograms for Numeric Columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df[col], bins=30, kde=True, color=\"blue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        path = f\"{col}_distribution.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "\n",
    "    heatmap_path = generate_heatmap(df)\n",
    "    if heatmap_path:\n",
    "        plot_paths.append(heatmap_path)\n",
    "    \n",
    "    return plot_paths  # âœ… Now it returns all plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4d51e3b-21bd-4636-9401-31df71a8abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(df):\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    if not numeric_df.empty:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        path = \"correlation_heatmap.png\"\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8c64796-6d07-40d1-96c7-c3963bbc582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* Running on public URL: https://c0849c74820a7174f2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c0849c74820a7174f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=eda_analysis,\n",
    "    inputs=gr.File(type=\"filepath\"),\n",
    "    outputs=[gr.Textbox(label=\"EDA Report\"), gr.Gallery(label=\"Data Visualizations\")],\n",
    "    title=\"ðŸ“Š LLM-Powered Exploratory Data Analysis (EDA)\",\n",
    "    description=\"Upload any dataset CSV file and get automated EDA insights with AI-powered analysis and visualizations.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio App\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
