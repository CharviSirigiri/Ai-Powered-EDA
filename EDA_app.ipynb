{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3cbea3-88c6-4ded-af2c-26a9e6e02753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e7c03d1-d955-4e51-be01-1653bbebd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_analysis(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Fill missing values with median for numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    # Fill missing values with mode for categorical columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Data Summary\n",
    "    summary = df.describe(include='all').to_string()\n",
    "    \n",
    "    # Missing Values\n",
    "    missing_values = df.isnull().sum().to_string()\n",
    "\n",
    "    # Generate AI Insights\n",
    "    insights = generate_ai_insights(summary)\n",
    "    \n",
    "    # Generate Data Visualizations\n",
    "    plot_paths = generate_visualizations(df)\n",
    "    \n",
    "    return f\"\\n Data Loaded Successfully!\\n\\n Summary:\\n{summary}\\n\\n Missing Values:\\n{missing_values}\\n\\n AI Insights:\\n{insights}\", plot_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd561c9c-bac0-4cc5-bcbb-0675518cf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_ai_insights(df_summary):\n",
    "    prompt = f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content'] if 'message' in response else response['messages'][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eacaee2d-b120-427d-abc1-535510540fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualizations(df):\n",
    "    plot_paths = []\n",
    "    \n",
    "    # Histograms for Numeric Columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df[col], bins=30, kde=True, color=\"blue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        path = f\"{col}_distribution.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "\n",
    "    heatmap_path = generate_heatmap(df)\n",
    "    if heatmap_path:\n",
    "        plot_paths.append(heatmap_path)\n",
    "    \n",
    "    return plot_paths  # âœ… Now it returns all plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e4d51e3b-21bd-4636-9401-31df71a8abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(df):\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "    if not numeric_df.empty:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        path = \"correlation_heatmap.png\"\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "        return path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
